#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿå¹¶å‘æ¨¡å‹æµ‹è¯•è„šæœ¬
ä½¿ç”¨å¤šçº¿ç¨‹å¿«é€Ÿæµ‹è¯•ç¬¬ä¸‰æ–¹ä»£ç†æ± ä¸­çš„æ‰€æœ‰æ¨¡å‹
æ”¯æŒæµå¼å’Œéæµå¼å“åº”æµ‹è¯•
"""

import requests
import json
import time
import urllib3
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class FastModelTester:
    def __init__(self, api_base: str, api_keys: list):
        self.api_base = api_base.rstrip('/')
        self.api_keys = api_keys
        self.key_index = 0
        self.lock = threading.Lock()

        # ç»“æœåˆ†ç±»
        self.stream_models = []
        self.non_stream_models = []
        self.failed_models = []

    def get_api_key(self):
        """çº¿ç¨‹å®‰å…¨è·å–APIå¯†é’¥"""
        with self.lock:
            key = self.api_keys[self.key_index]
            self.key_index = (self.key_index + 1) % len(self.api_keys)
            return key

    def quick_test_model(self, model_info):
        """å¿«é€Ÿæµ‹è¯•å•ä¸ªæ¨¡å‹"""
        model, index, total = model_info

        # å…ˆæµ‹è¯•æµå¼
        stream_result = self.test_stream(model)
        if stream_result['success']:
            print(f"[{index:2d}/{total}] âœ… {model[:40]}... æµå¼({stream_result['time']:.1f}s)")
            return {'type': 'stream', 'model': model, 'result': stream_result}

        # å†æµ‹è¯•éæµå¼
        non_stream_result = self.test_non_stream(model)
        if non_stream_result['success']:
            print(f"[{index:2d}/{total}] âœ… {model[:40]}... éæµå¼({non_stream_result['time']:.1f}s)")
            return {'type': 'non_stream', 'model': model, 'result': non_stream_result}

        # éƒ½å¤±è´¥
        error = stream_result.get('error', 'Unknown')[:15]
        print(f"[{index:2d}/{total}] âŒ {model[:40]}... {error}")
        return {'type': 'failed', 'model': model, 'result': stream_result}

    def test_stream(self, model):
        """æµ‹è¯•æµå¼å“åº”"""
        try:
            response = requests.post(
                f"{self.api_base}/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.get_api_key()}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": model,
                    "messages": [{"role": "user", "content": "1+1=?"}],
                    "max_tokens": 10,
                    "temperature": 0,
                    "stream": True
                },
                stream=True,
                timeout=6,
                verify=False
            )

            start_time = time.time()

            if response.status_code == 200:
                content = ""
                for line in response.iter_lines():
                    if line and line.decode('utf-8').startswith('data: '):
                        data_str = line.decode('utf-8')[6:]
                        if data_str.strip() == '[DONE]':
                            break
                        try:
                            data = json.loads(data_str)
                            if 'choices' in data and data['choices']:
                                delta = data['choices'][0].get('delta', {})
                                if 'content' in delta:
                                    content += delta['content']
                        except:
                            continue

                return {
                    'success': True,
                    'time': time.time() - start_time,
                    'answer': content.strip()
                }

            return {'success': False, 'error': f'HTTP {response.status_code}'}

        except Exception as e:
            return {'success': False, 'error': str(e)[:30]}

    def test_non_stream(self, model):
        """æµ‹è¯•éæµå¼å“åº”"""
        try:
            start_time = time.time()
            response = requests.post(
                f"{self.api_base}/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.get_api_key()}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": model,
                    "messages": [{"role": "user", "content": "1+1=?"}],
                    "max_tokens": 10,
                    "temperature": 0,
                    "stream": False
                },
                timeout=6,
                verify=False
            )

            if response.status_code == 200:
                data = response.json()
                if 'choices' in data and data['choices']:
                    answer = data['choices'][0]['message']['content'].strip()
                    return {
                        'success': True,
                        'time': time.time() - start_time,
                        'answer': answer
                    }

            return {'success': False, 'error': f'HTTP {response.status_code}'}

        except Exception as e:
            return {'success': False, 'error': str(e)[:30]}

    def run_fast_test(self, models, max_workers=8):
        """è¿è¡Œå¿«é€Ÿå¹¶å‘æµ‹è¯•"""
        print(f"ğŸš€ å¿«é€Ÿå¹¶å‘æµ‹è¯• {len(models)} ä¸ªæ¨¡å‹")
        print(f"âš¡ çº¿ç¨‹æ•°: {max_workers}")
        print(f"ğŸ”§ API: {self.api_base}")
        print("="*70)

        start_time = time.time()

        # å‡†å¤‡ä»»åŠ¡
        tasks = [(model, i+1, len(models)) for i, model in enumerate(models)]

        # å¹¶å‘æ‰§è¡Œ
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(self.quick_test_model, task) for task in tasks]

            for future in as_completed(futures):
                result = future.result()

                if result['type'] == 'stream':
                    self.stream_models.append(result)
                elif result['type'] == 'non_stream':
                    self.non_stream_models.append(result)
                else:
                    self.failed_models.append(result)

        total_time = time.time() - start_time

        # ç”ŸæˆæŠ¥å‘Š
        self.generate_fast_report(total_time)

        return {
            'stream_count': len(self.stream_models),
            'non_stream_count': len(self.non_stream_models),
            'failed_count': len(self.failed_models),
            'total_time': total_time
        }

    def generate_fast_report(self, total_time):
        """ç”Ÿæˆå¿«é€ŸæŠ¥å‘Š"""
        print(f"\n{'='*70}")
        print("ğŸ“Š å¿«é€Ÿæµ‹è¯•æŠ¥å‘Š")
        print(f"{'='*70}")

        total = len(self.stream_models) + len(self.non_stream_models) + len(self.failed_models)
        success_count = len(self.stream_models) + len(self.non_stream_models)

        print(f"ğŸ“‹ æµ‹è¯•ç»“æœ:")
        print(f"  â€¢ æ€»æ¨¡å‹æ•°: {total}")
        print(f"  â€¢ æ”¯æŒæµå¼: {len(self.stream_models)} ä¸ª")
        print(f"  â€¢ ä»…éæµå¼: {len(self.non_stream_models)} ä¸ª")
        print(f"  â€¢ å®Œå…¨å¤±è´¥: {len(self.failed_models)} ä¸ª")
        print(f"  â€¢ æˆåŠŸç‡: {success_count/total*100:.1f}%")
        print(f"  â€¢ æ€»è€—æ—¶: {total_time:.1f}ç§’")

        # æ˜¾ç¤ºæœ€å¿«çš„æµå¼æ¨¡å‹
        if self.stream_models:
            fastest_stream = min(self.stream_models, key=lambda x: x['result']['time'])
            print(f"\nğŸ† æœ€å¿«æµå¼æ¨¡å‹:")
            print(f"  {fastest_stream['model']}")
            print(f"  å“åº”æ—¶é—´: {fastest_stream['result']['time']:.2f}s")
            print(f"  å›ç­”: {fastest_stream['result']['answer']}")

        # æ˜¾ç¤ºæœ€å¿«çš„éæµå¼æ¨¡å‹
        if self.non_stream_models:
            fastest_non_stream = min(self.non_stream_models, key=lambda x: x['result']['time'])
            print(f"\nğŸ¥ˆ æœ€å¿«éæµå¼æ¨¡å‹:")
            print(f"  {fastest_non_stream['model']}")
            print(f"  å“åº”æ—¶é—´: {fastest_non_stream['result']['time']:.2f}s")
            print(f"  å›ç­”: {fastest_non_stream['result']['answer']}")

        # æ¨èé…ç½®
        all_working = self.stream_models + self.non_stream_models
        if all_working:
            best_model = min(all_working, key=lambda x: x['result']['time'])
            print(f"\nğŸ”§ æ¨èé…ç½®:")
            print(f'"model": "{best_model["model"]}"')

def main():
    # è¯»å–é…ç½®
    with open('config.json', 'r', encoding='utf-8') as f:
        config = json.load(f)

    # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¿€æ´»çš„ç¬¬ä¸‰æ–¹APIé…ç½®
    third_party_apis = config.get('third_party_apis', [])
    if not third_party_apis:
        print("âŒ æœªæ‰¾åˆ°ç¬¬ä¸‰æ–¹APIé…ç½®")
        return

    primary_api = None
    for api in third_party_apis:
        if api.get('is_active', True):
            primary_api = api
            break

    if not primary_api:
        primary_api = third_party_apis[0]

    api_base = primary_api['api_base']
    api_keys = primary_api['api_keys']
    all_models = primary_api['models']  # ç›´æ¥ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹åˆ—è¡¨

    print(f"ğŸ”§ ä½¿ç”¨ä»£ç†: {primary_api['name']}")
    print(f"ğŸŒ APIåœ°å€: {api_base}")
    print(f"ğŸ”‘ å¯†é’¥æ•°é‡: {len(api_keys)}")
    print(f"ğŸ¤– æ¨¡å‹æ•°é‡: {len(all_models)}")
    print()

    # åˆ›å»ºå¿«é€Ÿæµ‹è¯•å™¨
    tester = FastModelTester(api_base, api_keys)

    # è¿è¡Œå¿«é€Ÿæµ‹è¯•
    summary = tester.run_fast_test(all_models, max_workers=10)

    # ä¿å­˜ç»“æœ
    results = {
        'summary': summary,
        'stream_models': [{'model': m['model'], 'time': m['result']['time'], 'answer': m['result']['answer']} for m in tester.stream_models],
        'non_stream_models': [{'model': m['model'], 'time': m['result']['time'], 'answer': m['result']['answer']} for m in tester.non_stream_models],
        'failed_models': [{'model': m['model'], 'error': m['result']['error']} for m in tester.failed_models],
        'test_time': time.strftime('%Y-%m-%d %H:%M:%S')
    }

    with open('fast_test_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° fast_test_results.json")

if __name__ == "__main__":
    main()
